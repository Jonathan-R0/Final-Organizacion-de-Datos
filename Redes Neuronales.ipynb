{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2698d1bc",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff7f44",
   "metadata": {},
   "source": [
    "***1. Explicar en qué consiste Transfer Learning.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab800e0",
   "metadata": {},
   "source": [
    "Basicamente tiene que ver con reutilizar la información adquirida en aprendizaje anterior. Más información [aca](https://en.wikipedia.org/wiki/Transfer_learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5ce67",
   "metadata": {},
   "source": [
    "***3. En este ejercicio se plantea la aplicación de Redes Convoluciones para textos. Se tienen oraciones de un texto y se quiere clasificarlas en 10 categorías diferentes. Se quiere usar cada palabra del texto como una unidad indivisible.***\n",
    "\n",
    "***a) Explicar cómo se aplicaría una capa de convolución sobre el texto, cuáles serían los hiperparámetros a definir, y cuáles son los parámetros que debe encontrar la red neuronal.***\n",
    "\n",
    "***b) Diseñar y explicar una arquitectura para resolver el problema propuesto usando una única capa de\n",
    "convolución, una de pooling, una capa fully-connected y luego la capa final para clasificar. Justificar.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4a138",
   "metadata": {},
   "source": [
    "Transformamos cada oración en el conjunto de vectores que representan las palabras hasheadas. Los mismos son luego procesados por diferentes filtros convolucionales (producto interno) y entre los resultados de los filtros se puede hacer un max pooling para generar un vector reducible por una softmax.\n",
    "\n",
    "Los hiperparámetros son la cantidad de filtros a usar y los coeficientes de los mismos, la dimensionalidad de estos y los hiperparámetros de la red que le sigue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc61a03",
   "metadata": {},
   "source": [
    "***4. Se parte de imágenes RGB de 20x20 píxeles que se quieren clasificar entre 3 clases posibles con una red neuronal convolucional. Se aplica una capa convolucional del tipo “same” con 5 filtros de 3x3, luego se aplica una capa max pooling de 4x4 con stride de 4, a continuación una capa fully-connected y finalmente una capa softmax.***\n",
    "\n",
    "***a. Diagramar el modelo de red. ¿Cuántas neuronas tienen las dos últimas capas del modelo?***\n",
    "\n",
    "***b. ¿Cuántos parámetros se deben entrenar en total?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7017e0",
   "metadata": {},
   "source": [
    "Se puede diagramar en [esta página](http://alexlenail.me/NN-SVG/LeNet.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4beeb",
   "metadata": {},
   "source": [
    "***5. Se quiere aprender un clasificador tipo Perceptron para 6 puntos en el plano (A, B, C, D, E y F) y sus correspondientes clases (Ca, Cb, Cc, Cd, Ce y Cf) comenzando con el vector de pesos Wo = [1 1]. Se sabe que el algoritmo converge luego de 5 iteraciones:***\n",
    "\n",
    "***• En la primera iteración clasifica mal al punto “A”;***\n",
    "\n",
    "***• En la segunda iteración clasifica mal al punto “B”;***\n",
    "\n",
    "***• En la tercera iteración clasifica mal al punto “A”;***\n",
    "\n",
    "***• En la cuarta iteración clasifica mal al punto “F”;***\n",
    "\n",
    "***• En la quinta iteración todos los puntos quedan bien clasificados.***\n",
    "\n",
    "***Expresar el resultado final de W en función de los puntos A, B, C, D, E, F (no olvidar el término\n",
    "independiente).***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070ccb7",
   "metadata": {},
   "source": [
    "En la página 431 del apunte (sección 12.32) tenemos que el algorítmo de corrección de $W$ es:\n",
    "\n",
    "```\n",
    "while not done =>\n",
    "    tomar un punto y su clase (xi, yi)\n",
    "    if sign(w ∗ x) != y =>\n",
    "        w = w + y ∗ x\n",
    "```\n",
    "\n",
    "Por lo que en un principio `W := W + Ca * A` pues debe ajustarse producto de la mala clasificación. Si hacemos esto para el resto de malas clasificaciones llegamos a que: `W_final := W + 2 * Ca * A + Cb * B + Cf * F`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac24bf1",
   "metadata": {},
   "source": [
    "***6. Dados los puntos:***\n",
    "\n",
    "- $X_1 = (-2, 2) \\text{   Clase 1}$\n",
    "\n",
    "- $X_2 = (0, -2) \\text{   Clase 1}$\n",
    "\n",
    "- $X_3 = (4,  4) \\text{   Clase -1}$\n",
    "\n",
    "- $X_4 = (4,  5) \\text{   Clase -1}$\n",
    "\n",
    "***a. Entrenar un Perceptron utilizando el vector de pesos inicial Wo = [1 1] y learning rate 0,5 hasta que todos los puntos queden correctamente clasificados.***\n",
    "\n",
    "***b. Graficar los puntos y la separación de clases encontrada en base al vector de pesos resultante.***\n",
    "\n",
    "***c. Indicar si existe alguna mejor separación entre clases y, en caso afirmativo, indicar cómo poder\n",
    "encontrarla.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30baa9a",
   "metadata": {},
   "source": [
    "Sabemos que $\\theta_{n+1} = \\theta_n + \\gamma \\cdot (y_i - f_{\\theta_n}(x_i)) \\cdot x_i$\n",
    "\n",
    "Que $f_{\\theta_n}(x) = \\begin{cases}\n",
    "1 \\text{  if  } \\theta_{n}^t \\cdot x \\geq 0 \\\\\n",
    "-1 \\text{  else}\\\\\n",
    "\\end{cases}$\n",
    "\n",
    "Y que el learning rate es $\\gamma = 0.5$\n",
    "\n",
    "Por lo tanto vemos a ajustar nuestro $W_0$ con los datos incluidos ejecutando el algorítmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80f92906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruebo 4 y me  da  un  nuevo w = [-3.0, -4.0, 0.0]\n",
      "pruebo 1 y me  da  un  nuevo w = [-5.0, -2.0, 1.0]\n",
      "[-5.0, -2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from  random  import randint\n",
    "\n",
    "producto_interno = lambda x,y: sum([x[i]*y[i] for i in range(len(x))])\n",
    "suma_vectores    = lambda x,y: [x[i]+y[i] for i in range(len(x))]\n",
    "\n",
    "def activacion(xi,w):\n",
    "    prod = (producto_interno(xi,w) < 0)\n",
    "    return (prod) * -1 + (not prod) * 1\n",
    "\n",
    "def todas_correctas(x,c,w):\n",
    "    for i in range(len(x)):\n",
    "        if  activacion(x[i],w)  !=  c[i]:\n",
    "            return  False\n",
    "    return  True\n",
    "\n",
    "def perceptron(x,c,w,l):\n",
    "    x = [i+[w[-1]] for i in x]\n",
    "    cant_elementos  = len(x)\n",
    "    while not todas_correctas(x,c,w):\n",
    "        i = randint(0,cant_elementos-1)\n",
    "        if  activacion(x[i],w) != c[i]:\n",
    "            v = l * (c[i] - activacion(x[i],w))\n",
    "            w = suma_vectores(w, [i*v for i in  x[i]]) \n",
    "            print(f\"pruebo {i+1} y me  da  un  nuevo w = {w}\")  \n",
    "    print(w)\n",
    "\n",
    "perceptron([[-2,2],[0,-2],[4,4],[4,5]],[1,1,-1,-1],[1,1,1],0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892505e",
   "metadata": {},
   "source": [
    "***7. Dados los siguientes puntos en una dimensión (con sus correspondientes clases dadas por el signo):***\n",
    "\n",
    "$(1,+1), (5,-1), (0,+1), (6,-1), (4,+1), (7,-1)$\n",
    "\n",
    "***se aplica Perceptron para clasificar los puntos a partir del vector inicial de pesos w = [1 1]. Se observa que el perceptron converge luego de 33 pasos, y que en el proceso se clasificó 6 veces mal al primer punto, 13 veces mal al segundo puntos y 14 veces mal al quinto. En base a esto, se pide:***\n",
    "\n",
    "***a. Indicar el valor final del vector de pesos;***\n",
    "\n",
    "***b. Graficar el vector final de pesos y los puntos.***\n",
    "\n",
    "***c. indicar qué se podría hacer para lograr la convergencia de forma más rápida.***\n",
    "\n",
    "***Item adicional: para la propuesta dada en el item c, indicar en cuántos pasos convergería Perceptron y cuál sería el valor final del vector de pesos.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_definido(x,c,w,l,iteraciones):\n",
    "    x = [i+[1] for i in x]\n",
    "    cant_elementos  = len(x)\n",
    "    while not todas_correctas(x,c,w):\n",
    "        i = randint(0,cant_elementos-1)\n",
    "        if  activacion(x[i],w) != c[i]:\n",
    "            v = l * (c[i] - activacion(x[i],w))\n",
    "            w = suma_vectores(w, [i*v for i in  x[i]]) \n",
    "            print(f\"pruebo {i+1} y me  da  un  nuevo w = {w}\")  \n",
    "    print(w)\n",
    "    \n",
    "perceptron([[-2,2],[0,-2],[4,4],[4,5]],[1,1,-1,-1],[1,1,1],0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
