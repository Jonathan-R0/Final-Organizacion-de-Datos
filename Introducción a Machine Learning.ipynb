{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec139945",
   "metadata": {},
   "source": [
    "# Introducci√≥n a Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b9bac",
   "metadata": {},
   "source": [
    "***1. Explicar la diferencia entre un data-hub y un data-lake, y proponer un caso que ejemplifique el uso de cada uno.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f027a",
   "metadata": {},
   "source": [
    "En este [link](https://blog.semarchy.com/how-to-differentiate-a-data-hub-a-data-lake-and-a-data-warehouse#:~:text=They%20all%20look%20similar%20but,on%20analytical%20uses%20of%20data.) se puede ver con m√°s detalle la informaci√≥n, pero en esencia el data lake tiende a ser menos estructurado y a tener una menor calidad en el mismo, en comparaci√≥n al data-hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcca49",
   "metadata": {},
   "source": [
    "***2. Un sitio de ventas de autos quiere agregar una nueva funcionalidad de forma que cuando un usuario\n",
    "cargue su auto para la venta, el sitio le recomiende un precio para el mismo. Para ello quiere generar un modelo con XGBoost que al momento de cargar un nuevo aviso prediga el precio de venta.***\n",
    "\n",
    "***El set de datos sobre las publicaciones de autos posee estos atributos:***\n",
    "\n",
    "```\n",
    "fecha, marca, modelo, versi√≥n, a√±o, cantidad de puertas, segmento/tama√±o, equipamiento, kilometraje, estado, transmisi√≥n, color, tipo de combustible, motor, potencia, √∫nico due√±o, provincia, due√±o directo, precio.\n",
    "```\n",
    "\n",
    "***Indicar el proceso de feature engineering que realizar√≠a, indicando el detalle de los features que probar√≠a para armar un modelo de predicci√≥n mediante XGBoost. Dar un ejemplo de un row del set de datos final.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73c2be",
   "metadata": {},
   "source": [
    "Primero de todo, sabemos que todos los features categ√≥ricos con los que vamos a terminar, deben ser encodeados a formato num√©rico.\n",
    "\n",
    "Primero correr√≠a un random forest para ver que features actuan mejor, pues este modelo resulta ser sensible ante la diferencia de importancia entre columnas.\n",
    "\n",
    "Me quedar√≠a con las siguientes features:\n",
    "\n",
    "```\n",
    "fecha, segmento/tama√±o, kilometraje, transmisi√≥n (columna binaria), potencia, √∫nico due√±o (columna binaria), due√±o directo (columna binaria)\n",
    "```\n",
    "\n",
    "Har√≠a One Hot con:\n",
    "\n",
    "```\n",
    "marca, cantidad de puertas, estado, tipo de combustible, provincia \n",
    "```\n",
    "\n",
    "Har√≠a Mean Encoding con: \n",
    "\n",
    "```\n",
    "modelo, versi√≥n, equipamiento, color, motor\n",
    "```\n",
    "\n",
    "Reemplazar√≠a la columna `a√±o` con `edad` (`2021 - a√±o`).\n",
    "\n",
    "Ten√©s que ordenar las fechas para evitar predecir cosas que ya pasaron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff062ceb",
   "metadata": {},
   "source": [
    "***3. ¬øCu√°les de las siguientes t√©cnicas sirve para reducir el overfitting en XGBoost? Justificar.***\n",
    "\n",
    "‚Ä¢ ***Aumentar el n√∫mero de estimadores;***\n",
    "\n",
    "‚Ä¢ ***Aumentar el valor del hiperpar√°metro gamma;***\n",
    "\n",
    "‚Ä¢ ***Reducir el valor del hiperpar√°metro min-child-weight;***\n",
    "\n",
    "‚Ä¢ ***Reducir el learning rate;***\n",
    "\n",
    "‚Ä¢ ***Reducir el valor del hiperpar√°metro max-depth.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e2703",
   "metadata": {},
   "source": [
    "‚Ä¢ *Aumentar el n√∫mero de estimadores*: aumenta la cantidad de √°rboles lo que disminuye la probabilidad de tener decisiones sesgadas.\n",
    "\n",
    "‚Ä¢ *Aumentar el valor del hiperpar√°metro gamma*: [ü§∑‚Äç‚ôÇÔ∏è](https://stats.stackexchange.com/questions/418687/gamma-parameter-in-xgboost\n",
    ")\n",
    "\n",
    "‚Ä¢ *Reducir el valor del hiperpar√°metro min-child-weight*: cappea el peso de cierto nodo, tal que evita que el mismo splittee tan f√°cil.\n",
    "\n",
    "‚Ä¢ *Reducir el learning rate*: ü§∑‚Äç‚ôÇÔ∏è\n",
    "\n",
    "‚Ä¢ *Reducir el valor del hiperpar√°metro max-depth*: reduce el overfitting ya que, al tener menos hojas, evitamos tener predicciones tan r√≠gidas y ajustadas a nuestro set de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75819d",
   "metadata": {},
   "source": [
    "***4. Dados los siguientes puntos en una dimensi√≥n y sus labels para un problema de clasificaci√≥n binaria:***\n",
    "\n",
    "```\n",
    "(RED 0) (RED 0) (GREEN 1) (GREEN 0) (BLUE 0) (GREEN 0) (BLUE 0) (RED 1) (GREEN 1)\n",
    "```\n",
    "\n",
    "***aplicar dos algoritmos diferentes de mean encoding indicando c√≥mo quedar√≠a cada registro.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724477",
   "metadata": {},
   "source": [
    "Si aplicamos un `mean encoding` con $\\frac{P}{P+N}$ tenemos:\n",
    "\n",
    "```\n",
    "(RED 1/3) (RED 1/3) (GREEN 1/2) (GREEN 1/2) (BLUE 0) (GREEN 1/2) (BLUE 0) (RED 1/3) (GREEN 1/2)\n",
    "```\n",
    "\n",
    "Y si aplicamos `mean encoding` con $\\sum P$ tenemos:\n",
    "\n",
    "```\n",
    "(RED 1) (RED 1) (GREEN 2) (GREEN 2) (BLUE 0) (GREEN 2) (BLUE 0) (RED 1) (GREEN 2)\n",
    "```\n",
    "\n",
    "Siendo que $P$ y $N$ corresponden a los casos positivos y negativos respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e157ae",
   "metadata": {},
   "source": [
    "***5. Para el siguiente conjunto de registros, aplicar One-hot-encoding para la columna ‚Äú¬øHijos?‚Äù y\n",
    "Target-encoding para la columna ‚Äú¬øTrabajo?‚Äù. Sugerir adem√°s una forma de reducir posibles filtraciones de los labels para la columna codificada con Target-encoding.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a54c7",
   "metadata": {},
   "source": [
    "```\n",
    "Reg    Sexo   ¬øHijos?   ¬øTrabajo?   ¬øAuto?   ¬øSeguro de vida?\n",
    "1      M       S         S           S        s√≠\n",
    "2      F       N         N           N        no\n",
    "3      F       N         S           N        no\n",
    "4      M       N         S           S        no\n",
    "5      M       S         S           S        si\n",
    "6      M       S         N           S        s√≠\n",
    "7      F       S         S           N        no\n",
    "8      M       S         N           N        s√≠\n",
    "9      F       N         N           N        no\n",
    "10     F       N         S           S        s√≠\n",
    "11     F       S         N           N        no\n",
    "12     F       S         S           S        s√≠\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cdb23",
   "metadata": {},
   "source": [
    "Para hacer el target encoding sabemos que de las personas que trabajan, hay 4/7 con seguro de vida y de entre los vagos hay 2/5 con seguro de vida.\n",
    "\n",
    "El resultado es:\n",
    "\n",
    "```\n",
    "Reg    Sexo    Con hijos    Sin hijos    ¬øTrabajo?    ¬øAuto?    ¬øSeguro de vida?\n",
    "1      M       1            0            4/7          S         s√≠\n",
    "2      F       0            1            2/5          N         no\n",
    "3      F       0            1            4/7          N         no\n",
    "4      M       0            1            4/7          S         no\n",
    "5      M       1            0            4/7          S         si\n",
    "6      M       1            0            2/5          S         s√≠\n",
    "7      F       1            0            4/7          N         no\n",
    "8      M       1            0            2/5          N         s√≠\n",
    "9      F       0            1            2/5          N         no\n",
    "10     F       0            1            4/7          S         s√≠\n",
    "11     F       1            0            2/5          N         no\n",
    "12     F       1            0            4/7          S         s√≠\n",
    "```\n",
    "\n",
    "Podemos hacer *smoothing*. Primero calculamos `globalmean := mean(seguro de vida) = 6/12, alpha es un hiperpar√°metro, mean(target) := lo que est√° en trabajo ^^^` y en cada elemento dejamos:\n",
    "\n",
    "``` \n",
    "(mean(target) * nrows + globalmean * alpha)/(nrows + alpha)\n",
    "``` \n",
    "\n",
    "Recordemos que si $\\alpha \\rightarrow 0 \\implies$ volvemos a tener nuestro dataset original y si $\\alpha \\rightarrow \\infty$ todos los valores convergen en la media global.\n",
    "\n",
    "Por ejemplo, en la primera fila tendr√≠amos: $\\frac{\\frac{4}{7} \\cdot 12 + \\frac{6}{12} \\cdot \\alpha}{12 \\cdot \\alpha}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
